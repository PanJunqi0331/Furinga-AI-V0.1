import asyncio
import os
import requests
import pygame
import re
import time
import random
from config import SOVITS_API_URL, EMOTION_MAP, DEFAULT_REF, ACTIONS

# ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šè®¾ç½® HF é•œåƒï¼Œè§£å†³å›½å†…æ— æ³•ä¸‹è½½æ¨¡å‹çš„é—®é¢˜ ğŸ”¥ğŸ”¥ğŸ”¥
# å¿…é¡»åœ¨å¯¼å…¥ sentence_transformers ä¹‹å‰è®¾ç½®
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# ================= ğŸ“ é¢„è®¾æ ‡å‡†åŠ¨ä½œåº“ =================
TAG_ALIASES = {
    "å®‰å¿ƒ": "é‡Šæ€€", "æ”¾æ¾": "é‡Šæ€€", "å¹æ°”": "é‡Šæ€€", "åŸè°…": "é‡Šæ€€",
    "å–œæ¬¢": "çœŸè¯š", "æ„ŸåŠ¨": "çœŸè¯š", "æ¸©æŸ”": "çœŸè¯š", "è¡¨ç™½": "çœŸè¯š",
    "æƒ³è¦": "æ’’å¨‡", "æ±‚ä½ ": "æ’’å¨‡", "æ‹œæ‰˜": "æ’’å¨‡", "é¥¿": "æ’’å¨‡", "é¦‹": "æ’’å¨‡",
    "å¥½å¥‡": "æœŸå¾…", "æƒ³å¬": "æœŸå¾…", "æ„‰å¿«": "æœŸå¾…", "å¬æ•…äº‹": "æœŸå¾…",
    "æƒ³å¿µ": "ä¿¡ä»»", "æ€€å¿µ": "ä¿¡ä»»", "å›å¿†": "ä¿¡ä»»",
    "çƒ­": "åæ§½", "æ— è¯­": "åæ§½",  "æ™’": "åæ§½",
    "è¡¨æ¼”": "ä¸­äºŒ", "èµç¦": "ä¸­äºŒ", "ç¥æ˜": "ä¸­äºŒ", "å¨ä¸¥": "ä¸­äºŒ", "å®¡åˆ¤": "ä¸­äºŒ",
    "çŠ¹è±«": "çº ç»“", "ä¸ºéš¾": "çº ç»“", "çŸ›ç›¾": "çº ç»“",
    "å¥‡æ€ª": "ç–‘æƒ‘", "ä¸è§£": "ç–‘æƒ‘", "åæ‚”": "ç–‘æƒ‘",
    "æ¨è": "è‡ªä¿¡", "å‰å®³": "è‡ªä¿¡", "å¼º": "è‡ªä¿¡", "å¤©èµ‹": "è‡ªä¿¡",
    "å‰§é™¢": "è¥ä¸š", "ç»å…¸": "è¥ä¸š",
    "å“": "ææƒ§", "å‘æŠ–": "ææƒ§", "é˜´å½±": "ææƒ§",
    "åšæ¢¦": "å™©æ¢¦",
    "è‡ªæˆ‘ä»‹ç»": "ä»‹ç»", "å¤§æ˜æ˜Ÿ": "ä»‹ç»",
    "ç‹¬ç™½": "å­¤ç‹¬", "å¿ƒäº‹": "å­¤ç‹¬",
    "ç§˜å¯†": "äº¤æ˜“", "ç‚¹å¿ƒ": "äº¤æ˜“",
    "å¼€å¿ƒ": "å¼€å¿ƒ", "å¤§ç¬‘": "å¼€å¿ƒ", "å–œæ‚¦": "å¼€å¿ƒ", "å˜¿å˜¿": "å¼€å¿ƒ", "å¯çˆ±": "å¼€å¿ƒ", "å¥½": "å¼€å¿ƒ",
    "å…´å¥‹": "æ¿€åŠ¨", "æ˜Ÿæ˜Ÿçœ¼": "æ¿€åŠ¨",
    "æ„¤æ€’": "ç”Ÿæ°”", "æš´æ€’": "ç”Ÿæ°”", "ä¸çˆ½": "ç”Ÿæ°”", "å“¼": "ç”Ÿæ°”", "æ€’": "ç”Ÿæ°”",
    "éš¾è¿‡": "ä½è½", "ä¼¤å¿ƒ": "ä½è½", "å¤§å“­": "å“­", "å§”å±ˆ": "ä½è½", "é—æ†¾": "è¥ä¸š",
    "éœ‡æƒŠ": "åƒæƒŠ", "æƒŠè®¶": "åƒæƒŠ", "å‘†": "åƒæƒŠ", "åé€€": "åƒæƒŠ", "æ„£": "åƒæƒŠ",
    "æƒ³": "æ€è€ƒ", "æ²‰æ€": "æ€è€ƒ", "ç­‰ç­‰": "æ€è€ƒ", "æ‰˜è…®": "æ‰˜è„¸",
    "ç–‘æƒ‘": "ç–‘é—®", "ä¸æ‡‚": "ç–‘é—®", "è¯¶": "ç–‘é—®",
    "ç´¯": "å›°", "ç¡è§‰": "å›°", "å“ˆæ¬ ": "å›°",
    "ç¾æ¶©": "å®³ç¾", "è„¸çº¢": "å®³ç¾",
    "å°´å°¬": "æ±—", "æ“¦æ±—": "æ±—",
    "æ€•": "å®³æ€•", "æŠ–": "å®³æ€•",
    "æ™•å€’": "æ™•", "æ™•": "æ™•",
    "å˜èº«": "å˜èŠ’", "åˆ‡æ¢": "å˜è’",
    "æ€è€ƒ": "æ‰˜è„¸",
    "çœ¨çœ¼": "å–èŒ",
    "æ…Œå¼ ": "æ€¥",
    "ä¸è€çƒ¦": "ç”Ÿæ°”",  # ğŸ‘ˆ ä½ çš„æ ¸å¿ƒéœ€æ±‚ï¼šä¸è€çƒ¦ -> ç”Ÿæ°” (è¡¨ç°ä¸ºçš±çœ‰/ä¸çˆ½ï¼Œè€Œä¸æ˜¯ç¡è§‰)
    "æ— èŠ": "æ‰˜è„¸",    # æ— èŠ -> æ‰˜è…®æ€è€ƒ (æ¯”â€œå›°â€æ›´ç¬¦åˆæ— èŠå‘å‘†çš„çŠ¶æ€)
    "å«Œå¼ƒ": "å‚²å¨‡",    # å«Œå¼ƒ -> å‚²å¨‡/ç™½çœ¼
    "å˜²ç¬‘": "å¾—æ„",    # å˜²ç¬‘ -> å¾—æ„/å‰è…°
}

# ================= ğŸ§  æœ¬åœ°è¯­ä¹‰æ¨¡å‹åŠ è½½ =================
try:
    from sentence_transformers import SentenceTransformer, util
    import torch

    print("ğŸ§  [æœ¬åœ°æ¨¡å‹] æ­£åœ¨åŠ è½½è¯­ä¹‰åŒ¹é…æ¨¡å‹ (paraphrase-multilingual-MiniLM-L12-v2)...")
    # ç¬¬ä¸€æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä»é•œåƒç«™ä¸‹è½½çº¦ 470MB çš„æ¨¡å‹æ–‡ä»¶
    LOCAL_MODEL = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    # é¢„è®¡ç®—æ ‡å‡†åº“çš„å‘é‡
    VALID_EMOTIONS = list(ACTIONS.keys())
    EMOTION_EMBEDDINGS = LOCAL_MODEL.encode(VALID_EMOTIONS, convert_to_tensor=True)
    print("âœ… [æœ¬åœ°æ¨¡å‹] åŠ è½½å®Œæ¯•ï¼")
except ImportError:
    print("âš ï¸ [æœ¬åœ°æ¨¡å‹] æœªæ£€æµ‹åˆ° sentence-transformers åº“ï¼Œå°†ä½¿ç”¨å…³é”®è¯å…œåº•æ¨¡å¼ã€‚")
    print("ğŸ‘‰ å»ºè®®è¿è¡Œ: pip install sentence-transformers")
    LOCAL_MODEL = None
except Exception as e:
    print(f"âš ï¸ [æœ¬åœ°æ¨¡å‹] åŠ è½½å¤±è´¥: {e}")
    print("ğŸ’¡ æç¤ºï¼šå¦‚æœæ˜¯ç½‘ç»œé—®é¢˜ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å·²é…ç½® HF_ENDPOINT é•œåƒã€‚")
    LOCAL_MODEL = None


# ================= ğŸµ BGM ç®¡ç†å™¨ =================
class BGMManager:
    def __init__(self, bgm_folder="bgm"):
        self.bgm_folder = bgm_folder
        if not os.path.exists(self.bgm_folder):
            os.makedirs(self.bgm_folder)

        self.current_category = None
        self.categories = ["sleep", "sad", "happy", "jazz", "opera", "tension", "relax"]
        self.playlist = {cat: [] for cat in self.categories}
        self._scan_files()

    def _scan_files(self):
        count = 0
        for filename in os.listdir(self.bgm_folder):
            if not filename.endswith(".ogg"): continue
            assigned = False
            for cat in self.categories:
                if filename.startswith(cat):
                    self.playlist[cat].append(filename)
                    assigned = True
                    count += 1
                    break
            if not assigned:
                self.playlist["relax"].append(filename)
        print(f"ğŸµ [BGMåº“] å…±åŠ è½½ {count} é¦–éŸ³ä¹ã€‚")

    def update_state(self, mood, energy, activity_text=""):
        target = "relax"
        if energy < 20 or "ç¡" in activity_text:
            target = "sleep"
        elif "æ­Œå‰§" in activity_text or "æ¼”å‡º" in activity_text or "å®¡åˆ¤" in activity_text:
            target = "opera"
        elif "ç ”ç©¶" in activity_text or "å¤æ‚" in activity_text or "æ€è€ƒ" in activity_text or "ä»£ç " in activity_text:
            target = "tension"
        elif mood < 35:
            target = "sad"
        elif mood > 80:
            current_hour = time.localtime().tm_hour
            if current_hour >= 19 or current_hour <= 5:
                target = "jazz"
            else:
                target = "happy"
        else:
            target = "relax"
        self._play_random(target)

    def _play_random(self, category):
        if category == self.current_category and pygame.mixer.music.get_busy():
            return
        file_list = self.playlist.get(category)
        if not file_list:
            if category != "relax":
                self._play_random("relax")
            return
        chosen = random.choice(file_list)
        path = os.path.join(self.bgm_folder, chosen)
        # print(f"ğŸ¼ [BGM] åˆ‡æ¢å¿ƒæƒ…: {category.upper()} -> æ­£åœ¨æ’­æ”¾: {chosen}") # å‡å°‘åˆ·å±
        try:
            if pygame.mixer.music.get_busy():
                pygame.mixer.music.fadeout(1500)
                time.sleep(1.5)
            pygame.mixer.music.load(path)
            pygame.mixer.music.set_volume(0.35)
            pygame.mixer.music.play(-1, fade_ms=2000)
            self.current_category = category
        except Exception as e:
            print(f"âŒ BGMæ’­æ”¾å¤±è´¥: {e}")


# ================= ğŸ—£ï¸ è¯­éŸ³ç®¡ç†å™¨ (æœ¬åœ°æ¨¡å‹ç‰ˆ) =================
class AudioManager:
    def __init__(self):
        try:
            if not pygame.mixer.get_init():
                pygame.mixer.init(frequency=44100, size=-16, channels=2, buffer=4096)
                pygame.mixer.set_num_channels(8)
        except Exception as e:
            print(f"âš ï¸ æ··éŸ³å™¨åˆå§‹åŒ–è­¦å‘Š: {e}")

        self.stop_event = asyncio.Event()
        self.session = requests.Session()
        self.last_hand_action_time = 0
        self.voice_channel = pygame.mixer.Channel(1)

    def stop(self):
        self.stop_event.set()
        if self.voice_channel.get_busy():
            self.voice_channel.stop()

    def _get_ref_audio_path(self, relative_path):
        abs_path = os.path.abspath(relative_path)
        if not os.path.exists(abs_path):
            filename = os.path.basename(relative_path)
            root_path = os.path.abspath(filename)
            if os.path.exists(root_path):
                abs_path = root_path
            else:
                return None
        return abs_path.replace("\\", "/")

    # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒï¼šæœ¬åœ°è¯­ä¹‰åŒ¹é… ğŸ”¥ğŸ”¥ğŸ”¥
    def _map_emotion_local(self, raw_tag):
        """
        ä½¿ç”¨æœ¬åœ°æ¨¡å‹è®¡ç®— raw_tag ä¸ VALID_EMOTIONS çš„ä½™å¼¦ç›¸ä¼¼åº¦
        """
        if LOCAL_MODEL is None:
            # é™çº§æ–¹æ¡ˆï¼šå…³é”®è¯åŒ¹é…
            if any(c in raw_tag for c in ["çº¢", "ç¾", "ä½å¤´", "èº²", "æ‚"]): return "å®³ç¾"
            if any(c in raw_tag for c in ["æ°”", "å“¼", "è·º", "æ€’", "çª"]): return "ç”Ÿæ°”"
            if any(c in raw_tag for c in ["ç¬‘", "ä¹", "å“ˆ", "å–œ", "è½¬åœˆ"]): return "å¼€å¿ƒ"
            if any(c in raw_tag for c in ["æƒŠ", "å‘†", "æ„£", "è¯¶", "å•Š"]): return "åƒæƒŠ"
            if any(c in raw_tag for c in ["å“­", "æ³ª", "æ‚²", "å‘œ"]): return "å“­"
            if any(c in raw_tag for c in ["å›°", "ç¡", "æ¬ ", "ç´¯", "è¿·ç³Š"]): return "å›°"
            return "æ­£å¸¸"

        try:
            # 1. è®¡ç®—è¾“å…¥æ ‡ç­¾çš„å‘é‡
            input_embedding = LOCAL_MODEL.encode(raw_tag, convert_to_tensor=True)

            # 2. è®¡ç®—ä¸æ‰€æœ‰æ ‡å‡†åŠ¨ä½œçš„ç›¸ä¼¼åº¦
            cos_scores = util.cos_sim(input_embedding, EMOTION_EMBEDDINGS)[0]

            # 3. æ‰¾åˆ°å¾—åˆ†æœ€é«˜çš„åŠ¨ä½œ
            best_score_idx = torch.argmax(cos_scores).item()
            best_score = cos_scores[best_score_idx].item()
            best_emotion = VALID_EMOTIONS[best_score_idx]

            # 4. é˜ˆå€¼åˆ¤å®š (å¦‚æœç›¸ä¼¼åº¦å¤ªä½ï¼Œè¯´æ˜ä¸æ²¾è¾¹)
            if best_score > 0.4:  # 0.35 æ˜¯ç»éªŒå€¼ï¼Œæ¯”è¾ƒå®½æ¾
                print(f"ğŸ§  [è¯­ä¹‰åŒ¹é…] '{raw_tag}' â‰ˆ '{best_emotion}' (ç›¸ä¼¼åº¦: {best_score:.2f})")
                return best_emotion
            else:
                print(f"ğŸ§  [è¯­ä¹‰åŒ¹é…] '{raw_tag}' è¯­ä¹‰ä¸æ˜ (æœ€é«˜åŒ¹é…: {best_emotion}, {best_score:.2f}) -> å›é€€æ­£å¸¸")
                return "æ­£å¸¸"

        except Exception as e:
            print(f"âš ï¸ åŒ¹é…å‡ºé”™: {e}")
            return "æ­£å¸¸"

    async def _tts_producer(self, sentences, audio_queue, emotion):
        print(f"ğŸ­ [éŸ³é¢‘å·¥å‚] å¼€å§‹å¤„ç† {len(sentences)} å¥è¯ (æƒ…æ„Ÿ: {emotion})...")
        speed = 1.0
        if emotion in ["ç”Ÿæ°”", "æ€¥", "æ¿€åŠ¨", "åƒæƒŠ"]:
            speed = 1.2  # è¯­é€ŸåŠ å¿«
        elif emotion in ["å›°", "ä½è½", "æ‚²ä¼¤", "æ— èŠ"]:
            speed = 0.85  # è¯­é€Ÿå˜æ…¢
        elif emotion in ["å‚²å¨‡", "å¾—æ„"]:
            speed = 1.1  # ç¨å¾®è½»å¿«
        for i, text in enumerate(sentences):
            if self.stop_event.is_set(): break
            clean_text = re.sub(r"\[.*?\]|\(.*?\)|\ï¼ˆ.*?\ï¼‰|\ã€.*?\ã€‘", "", text).strip()
            if not clean_text: continue

            ref_data = EMOTION_MAP.get(emotion, DEFAULT_REF)
            ref_path = self._get_ref_audio_path(ref_data["file"])
            if not ref_path: continue

            payload = {
                "text": clean_text, "text_lang": "zh", "ref_audio_path": ref_path,
                "prompt_text": ref_data["text"], "prompt_lang": "zh",
                "text_split_method": "cut5", "batch_size": 1,
                "speed_factor": speed,  # åº”ç”¨åŠ¨æ€è¯­é€Ÿ
            }
            try:
                loop = asyncio.get_event_loop()
                response = await loop.run_in_executor(None,
                                                      lambda: self.session.post(f"{SOVITS_API_URL}/tts", json=payload))
                if response.status_code == 200 and len(response.content) > 1000:
                    filename = f"temp_{int(time.time())}_{i}.wav"
                    with open(filename, "wb") as f: f.write(response.content)
                    await audio_queue.put((filename, text))
            except Exception as e:
                print(f"âŒ APIå¼‚å¸¸: {e}")
        await audio_queue.put(None)

    async def _audio_player(self, audio_queue, vts, emotion):
        first_sentence = True
        while True:
            if self.stop_event.is_set():
                while not audio_queue.empty():
                    try:
                        audio_queue.get_nowait(); audio_queue.task_done()
                    except:
                        break
                break
            item = await audio_queue.get()
            if item is None: break
            filename, text = item
            if not os.path.exists(filename): continue

            print(f"â–¶ï¸ æ­£åœ¨æ’­æ”¾: {text[:15]}...")
            if vts and first_sentence:
                if emotion in ACTIONS: await vts.trigger_action(emotion)
                await vts.look_at_camera()
                first_sentence = False

            try:
                sound = pygame.mixer.Sound(filename)
                self.voice_channel.play(sound)
                while self.voice_channel.get_busy():
                    if self.stop_event.is_set(): self.voice_channel.stop(); return
                    await asyncio.sleep(0.1)
            except Exception as e:
                print(f"âš ï¸ æ’­æ”¾é”™è¯¯: {e}")
            finally:
                await asyncio.sleep(0.1)
                if os.path.exists(filename):
                    try:
                        os.remove(filename)
                    except:
                        pass
        if not self.stop_event.is_set() and vts:
            await vts.look_at_camera()

    async def speak(self, full_text, vts):
        if not full_text: return
        emotion = "æ­£å¸¸"
        match = re.search(r"\[(.*?)\]", full_text)

        if match:
            raw_tag = match.group(1)
            # 1. ç²¾å‡†åŒ¹é…
            if raw_tag in ACTIONS:
                emotion = raw_tag
            # 2. åŒä¹‰è¯è¡¨åŒ¹é…
            elif raw_tag in TAG_ALIASES:
                emotion = TAG_ALIASES[raw_tag]
                print(f"ğŸ”§ [è‡ªåŠ¨ä¿®æ­£] '{raw_tag}' -> '{emotion}'")
            # 3. ğŸ”¥ æœ¬åœ°æ¨¡å‹è¯­ä¹‰åŒ¹é…
            else:
                emotion = self._map_emotion_local(raw_tag)

        clean_text = re.sub(r"\[.*?\]|\(.*?\)|\ï¼ˆ.*?\ï¼‰|\ã€.*?\ã€‘", "", full_text).strip()
        sentences = []
        for part in re.split(r'(ã€‚|ï¼|ï¼Ÿ|\n|â€¦)', clean_text):
            if part.strip(): sentences.append(part.strip())

        queue = asyncio.Queue()
        self.stop_event.clear()
        await asyncio.gather(self._tts_producer(sentences, queue, emotion), self._audio_player(queue, vts, emotion))